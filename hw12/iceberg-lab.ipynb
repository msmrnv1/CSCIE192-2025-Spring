{
	"metadata": {
		"kernelspec": {
			"display_name": "Glue Interactive Sessions",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "# AWS Glue Studio Notebook\n##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "#### Optional: Run this cell to see available notebook commands (\"magics\").\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%help",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "### This notebook shows examples of using Glue to explore and handle iceberg data\nTo follow this example notebook, execute the cells in order.  \nThe keyboard shortcut to execute the current cell and jump to the following is: Shift+Enter.",
			"metadata": {}
		},
		{
			"cell_type": "markdown",
			"source": "####  Run this cell to set up and start your interactive session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 4.0\n%worker_type G.1X\n%number_of_workers 2\n%spark_conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions --conf spark.sql.catalog.glue_catalog=org.apache.iceberg.spark.SparkCatalog --conf spark.sql.catalog.glue_catalog.warehouse=s3://es-datalake/silver/iceberg-example/ --conf spark.sql.catalog.glue_catalog.catalog-impl=org.apache.iceberg.aws.glue.GlueCatalog --conf spark.sql.catalog.glue_catalog.io-impl=org.apache.iceberg.aws.s3.S3FileIO --conf spark.sql.defaultCatalog=glue_catalog\n%%configure\n{\n   \"--datalake-formats\": \"iceberg\"\n}",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.8 \nCurrent idle_timeout is None minutes.\nidle_timeout has been set to 2880 minutes.\nSetting Glue version to: 4.0\nPrevious worker type: None\nSetting new worker type to: G.1X\nPrevious number of workers: None\nSetting new number of workers to: 2\nPrevious Spark configuration: None\nSetting new Spark configuration to: spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions --conf spark.sql.catalog.glue_catalog=org.apache.iceberg.spark.SparkCatalog --conf spark.sql.catalog.glue_catalog.warehouse=s3://es-datalake/silver/iceberg-example/ --conf spark.sql.catalog.glue_catalog.catalog-impl=org.apache.iceberg.aws.glue.GlueCatalog --conf spark.sql.catalog.glue_catalog.io-impl=org.apache.iceberg.aws.s3.S3FileIO --conf spark.sql.defaultCatalog=glue_catalog\nThe following configurations have been updated: {'--datalake-formats': 'iceberg'}\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "%spark_conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions --conf spark.sql.catalog.glue_catalog=org.apache.iceberg.spark.SparkCatalog --conf spark.sql.catalog.glue_catalog.warehouse=s3://es-datalake/silver/iceberg-example/ --conf spark.sql.catalog.glue_catalog.catalog-impl=org.apache.iceberg.aws.glue.GlueCatalog --conf spark.sql.catalog.glue_catalog.io-impl=org.apache.iceberg.aws.s3.S3FileIO --conf spark.sql.defaultCatalog=glue_catalog",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 9,
			"outputs": [
				{
					"name": "stdout",
					"text": "Previous Spark configuration: spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions --conf spark.sql.catalog.glue_catalog=org.apache.iceberg.spark.SparkCatalog --conf spark.sql.catalog.glue_catalog.warehouse=s3://es-datalake/silver/iceberg-example/ --conf spark.sql.catalog.glue_catalog.catalog-impl=org.apache.iceberg.aws.glue.GlueCatalog --conf spark.sql.catalog.glue_catalog.io-impl=org.apache.iceberg.aws.s3.S3FileIO --conf spark.sql.defaultCatalog=glue_catalog\nSetting new Spark configuration to: spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions --conf spark.sql.catalog.glue_catalog=org.apache.iceberg.spark.SparkCatalog --conf spark.sql.catalog.glue_catalog.warehouse=s3://es-datalake/silver/iceberg-example/ --conf spark.sql.catalog.glue_catalog.catalog-impl=org.apache.iceberg.aws.glue.GlueCatalog --conf spark.sql.catalog.glue_catalog.io-impl=org.apache.iceberg.aws.s3.S3FileIO --conf spark.sql.defaultCatalog=glue_catalog\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "catalog_name = \"glue_catalog\"\nbucket_name = \"es-datalake\"\nbucket_prefix = \"silver/iceberg-example2/\"\ndatabase_name = \"iceberg_sql2\"\ntable_name = \"medicare\"\nwarehouse_path = f\"s3://{bucket_name}/{bucket_prefix}\"",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Trying to create a Glue session for the kernel.\nSession Type: glueetl\nWorker Type: G.1X\nNumber of Workers: 2\nIdle Timeout: 2880\nSession ID: 8c9409a6-e5ce-4018-a5cc-b9823d07d93f\nApplying the following default arguments:\n--glue_kernel_version 1.0.8\n--enable-glue-datacatalog true\n--datalake-formats iceberg\n--conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions --conf spark.sql.catalog.glue_catalog=org.apache.iceberg.spark.SparkCatalog --conf spark.sql.catalog.glue_catalog.warehouse=s3://es-datalake/silver/iceberg-example/ --conf spark.sql.catalog.glue_catalog.catalog-impl=org.apache.iceberg.aws.glue.GlueCatalog --conf spark.sql.catalog.glue_catalog.io-impl=org.apache.iceberg.aws.s3.S3FileIO --conf spark.sql.defaultCatalog=glue_catalog\nWaiting for session 8c9409a6-e5ce-4018-a5cc-b9823d07d93f to get into ready status...\nSession 8c9409a6-e5ce-4018-a5cc-b9823d07d93f has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from awsglue.context import GlueContext\nfrom awsglue.job import Job\nfrom pyspark.context import SparkContext\n\nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "query = f\"\"\"\nCREATE DATABASE IF NOT EXISTS {database_name}\n\"\"\"\nspark.sql(query)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "DataFrame[]\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# If you data doesn't have a table in the catalog, you can use a temporary view to use SQL\n# Here we read all the CSV files under the indicated s3 path\nmedicareDF = spark.read.csv(\"s3://awsglue-datasets/examples/medicare/\", header=True)\n# If there data has a reasonable size (like in this case), we can cache in memory/disk (depending on cluster size) \n# so after the first query, the following no longer have to go to read and parse from s3\nmedicareDF.cache()\n# Instead of using the DataFrame API, you can register it as a view for SQL usage like this:\nmedicareDF.registerTempTable(\"tmp_medicare\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "query = f\"\"\"\nCREATE TABLE {catalog_name}.{database_name}.{table_name}\nUSING iceberg\nLOCATION '{warehouse_path}'\nTBLPROPERTIES (\"format-version\"=\"2\")\nAS SELECT * FROM tmp_medicare\n\"\"\"\nspark.sql(query)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "DataFrame[]\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "%%sql\nSELECT * FROM glue_catalog.iceberg_sql2.medicare.history",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 6,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------------+-------------------+---------+-------------------+\n|     made_current_at|        snapshot_id|parent_id|is_current_ancestor|\n+--------------------+-------------------+---------+-------------------+\n|2025-04-15 03:53:...|6277996127910655019|     null|               true|\n+--------------------+-------------------+---------+-------------------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "query = f\"\"\"\nINSERT INTO {catalog_name}.{database_name}.{table_name}\n(SELECT * FROM tmp_{table_name})\n\"\"\"\nspark.sql(query)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 6,
			"outputs": [
				{
					"name": "stdout",
					"text": "DataFrame[]\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "%%sql\nSELECT * FROM glue_catalog.iceberg_sql2.medicare.history",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 8,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------------+-------------------+-------------------+-------------------+\n|     made_current_at|        snapshot_id|          parent_id|is_current_ancestor|\n+--------------------+-------------------+-------------------+-------------------+\n|2025-04-15 03:53:...|6277996127910655019|               null|               true|\n|2025-04-15 03:56:...|5173792975111062545|6277996127910655019|               true|\n+--------------------+-------------------+-------------------+-------------------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "%%sql\nSELECT count(*) FROM glue_catalog.iceberg_sql2.medicare",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 9,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------+\n|count(1)|\n+--------+\n|  326130|\n+--------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "%%sql\nSELECT count(*) FROM glue_catalog.iceberg_sql2.medicare for version as of 6277996127910655019",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 10,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------+\n|count(1)|\n+--------+\n|  163065|\n+--------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Queries in Athena\nThe same queries in the Athena SQL format are\n```\nselect count(*) from medicare;\n\nselect * from \"medicare$history\";\n\nselect count(*) from medicare for version as of 6277996127910655019;\n```\n",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "# Queries in Athena SQL format\n\n# select count(*) from medicare;\n\n# select * from \"medicare$history\";\n\n# select count(*) from medicare for version as of 6277996127910655019;",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		}
	]
}